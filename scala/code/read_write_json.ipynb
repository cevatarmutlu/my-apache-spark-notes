{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Açıklama\n",
    "\n",
    "JSON dosyalarını Scala Spark ile Okuma ve Yazma.\n",
    "\n",
    "Bu dosyadaki adımlar aşağıdaki sıradadır:\n",
    "\n",
    "1. Spark Session başlatılır\n",
    "2. JSON dosyası okunur\n",
    "3. JSON dosyası üzerinde basit bir filtreleme yapılır. JSON yazmak için yapılması elzem değil\n",
    "4. JSON dosyası belirtilen dizine yazılır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.152:4040\n",
       "SparkContext available as 'sc' (version = 3.2.0, master = local[*], app id = local-1642957459717)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@61278e8d\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Spark Session başlatılır\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"JSON READ and Write Operation\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------------+-------+------+--------+-------+\n",
      "|categoryId|itemId|          orderDate|orderId| price|sellerId| status|\n",
      "+----------+------+-------------------+-------+------+--------+-------+\n",
      "|         1|     1|2021-03-05 10:03:23|      1|   3.0|     100|CREATED|\n",
      "|         1|     2|2021-03-05 10:22:55|      1|  10.0|     100|CREATED|\n",
      "|         1|     3|2021-03-05 10:45:23|      1| 250.0|     100|CREATED|\n",
      "|         1|     4|2021-03-05 15:22:41|      1|   5.0|     200|CREATED|\n",
      "|         2|     5|2021-03-05 15:00:11|      1|   5.0|     200|CREATED|\n",
      "|         3|     6|2021-03-05 03:15:12|      2|  10.0|     100|CREATED|\n",
      "|         4|     7|2021-03-05 03:51:05|      2|  30.0|     200|CREATED|\n",
      "|         4|     8|2021-03-05 02:59:04|      2|  50.0|     200|CREATED|\n",
      "|         1|     9|2021-03-05 01:01:27|      2| 150.0|     300|CREATED|\n",
      "|         1|    10|2021-03-05 15:05:54|      3|1000.0|     100|CREATED|\n",
      "|         2|    11|2021-03-05 17:11:55|      3| 150.0|     100|CREATED|\n",
      "|         2|    12|2021-03-05 21:15:13|      3| 500.0|     200|CREATED|\n",
      "|         5|    13|2021-03-06 22:48:15|      1|   5.0|     100|CREATED|\n",
      "|         5|    14|2021-03-06 02:42:27|      1|  10.0|     100|CREATED|\n",
      "|         7|    15|2021-03-06 03:33:00|      2|   2.0|     100|CREATED|\n",
      "|         2|    16|2021-03-06 07:03:33|      2|   5.0|     200|CREATED|\n",
      "|         2|    17|2021-03-06 05:09:19|      2|   5.0|     200|CREATED|\n",
      "|         3|    18|2021-03-06 13:19:11|      3| 250.0|     300|CREATED|\n",
      "|         4|    19|2021-03-06 15:27:10|      4| 300.0|     300|CREATED|\n",
      "|         3|    20|2021-03-06 19:27:00|      5|  10.0|     300|CREATED|\n",
      "+----------+------+-------------------+-------+------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "json_file: String = ../../datasets/json/orders_input.json\n",
       "json_df: org.apache.spark.sql.DataFrame = [categoryId: bigint, itemId: bigint ... 5 more fields]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// JSON dosyası okunur\n",
    "\n",
    "val json_file: String = \"../../datasets/json/orders_input.json\"\n",
    "\n",
    "val json_df = spark.read.json(json_file) // Okunan JSON dosyası bir DataFrame olarak okunur. \n",
    "// `json_df` bir DataFrame nesnesidir. Bu cell' in out kısmında görebilirsiniz.\n",
    "\n",
    "json_df.show() // DataFrame' in 20 satırı ekrana basılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------------+-------+------+--------+-------+\n",
      "|categoryId|itemId|          orderDate|orderId| price|sellerId| status|\n",
      "+----------+------+-------------------+-------+------+--------+-------+\n",
      "|         1|     3|2021-03-05 10:45:23|      1| 250.0|     100|CREATED|\n",
      "|         1|     9|2021-03-05 01:01:27|      2| 150.0|     300|CREATED|\n",
      "|         1|    10|2021-03-05 15:05:54|      3|1000.0|     100|CREATED|\n",
      "|         2|    11|2021-03-05 17:11:55|      3| 150.0|     100|CREATED|\n",
      "|         2|    12|2021-03-05 21:15:13|      3| 500.0|     200|CREATED|\n",
      "|         3|    18|2021-03-06 13:19:11|      3| 250.0|     300|CREATED|\n",
      "|         4|    19|2021-03-06 15:27:10|      4| 300.0|     300|CREATED|\n",
      "|         1|    21|2021-03-06 09:22:03|      5| 200.0|     300|CREATED|\n",
      "|         1|    22|2021-03-06 16:17:09|      5|  60.0|     300|CREATED|\n",
      "|         1|    23|2021-03-06 00:00:01|      6| 450.0|     300|CREATED|\n",
      "+----------+------+-------------------+-------+------+--------+-------+\n",
      "\n",
      "root\n",
      " |-- categoryId: long (nullable = true)\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- orderDate: string (nullable = true)\n",
      " |-- orderId: long (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- sellerId: long (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "high_price: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [categoryId: bigint, itemId: bigint ... 5 more fields]\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// JSON dosyası üzerinde basit bir filtreleme yapılır. JSON yazmak için yapılması elzem değil\n",
    "\n",
    "val high_price =  json_df.filter(\"price > 50\")\n",
    "\n",
    "high_price.show() // DataFrame' in 20 satırı ekrana basılır.\n",
    "\n",
    "high_price.printSchema() // DataFrame' deki kolonların schema' sını ve tiplerini gösterir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT: Yukarıdaki cell' in out kısmında high_price' in `Dataset[Row]` nesnesi olduğunu yazmaktadır. `Dataset[Row]` ifadesi `DataFrame` demektir.\n",
    "\n",
    "Kaynak: https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "// JSON dosyası belirtilen dizine yazılır\n",
    "\n",
    "high_price.write.json(\"json_file\")\n",
    "// Spark' ta yukarıdaki işlem gerçekleştirildikten sonra `json_file` adında bir klasör oluşur ve\n",
    "// JSON dosyası `json_file` klasörünün içindeki `part-` ile başlayan dosyadır."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
