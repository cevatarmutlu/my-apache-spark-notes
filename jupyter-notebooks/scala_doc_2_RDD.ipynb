{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RDD Programming Guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Overview](https://spark.apache.org/docs/latest/rdd-programming-guide.html#overview)\n",
    "\n",
    "**High level** her Spark uygulaması ***driver program*** denen bir şeyden oluşur. Bu ***driver program*** kullanıcın *main* fonksiyonunu çalıştırır ve **cluster** üzerinde çeşitli paralel işlemleri execute eder.\n",
    "\n",
    "Spark' ın sağladığı main **absraction** ***resilient distributed dataset*** (RDD) olmaktadır. RDD, bir elemanlar kümesidir(collection of elements). RDD, cluster üzerindeki node' lar boyunca partition' lara (bölümlere) ayrılmıştır. RDD' lerin node' lara bölünmesi sayesinde paralel işlemler yapılabilmektedir.\n",
    "\n",
    "RDD' ler çeşitli formattaki dosyalardan ya da driver program içindeki collectionlardan oluşturulabilir (collectiondan kasıt sanırım scala dizileri ya da hangi dili kullanıyorsanız).\n",
    "\n",
    "Eğer bir RDD' yi çok sık şekilde kullanacaksanız Spark' a bu RDD' yi cache al diyebiliyorsunuz.\n",
    "\n",
    "RDD' ler node' larda oluşan hatalardan otomatik olarak recover edilirler Sanırım hiç hata olmamış hallerine geri döndürülürler.\n",
    "\n",
    "___\n",
    "\n",
    "Spark' ın ikinci absraction' u paralel işlemler kullanılan ***shared variables*** tir.\n",
    "\n",
    "Sanırım Spark' ta Default olarak şöyle bir şey gerçekleştiriliyor: Spark' ta paralel bir işlem başladığında node' lara task' lar dağıtılıyor. Bu task' lar için gerekli olan variable' lar node' larda çalışacak olan fonksiyona kopyalanıyor.\n",
    "\n",
    "Bazen bir tane değişkenin tasklar arasında ya da task ile driver program arasında shared edilmesi gerekiyormuş. Bu özelliğin var olma sebebi bu.\n",
    "\n",
    "Sparkta iki tane shared variables türü varmış:\n",
    "***broadcast variables***: Tüm nodeların memory' lerindeki bir value' yi cache almak için kullanılır. (Ne demek bilmiyorum.)\n",
    "***accumulators***: Yanlızca \"added\" değişkenlermiş. Örneğin counters ve sum. (Ne demek bilmiyorum as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Resilient Distributed Datasets (RDDs)](https://spark.apache.org/docs/latest/rdd-programming-guide.html#resilient-distributed-datasets-rdds)\n",
    "\n",
    "Spark ***Resilient Distributed Datasets*** kavramı etrafında döner. RDD, paralel olarak çalıştırılabilen, hata toleranslı elementler koleksiyonudur (**fault-tolerant** collection of elements).\n",
    "\n",
    "RDD iki şekilde oluşturulur: <br/>\n",
    "birincisi driver programda bulunan colloection' u ***parallelizing*** ederek. <br/>\n",
    "ikincisi external storage system' da bulunan bir dataset' e referans vererek. external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Parallelized Collections](https://spark.apache.org/docs/latest/rdd-programming-guide.html#parallelized-collections)\n",
    "\n",
    "Bir parallelized collection, sizin driver programınızda bulunan collection' ı parametre olarak olan ***SparkContext***' in ***parallelize*** metodu ile oluşturulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: Array[Int] = Array(1, 2, 3, 4, 5)\n",
       "distData: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:26\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Array(1, 2, 3, 4, 5)\n",
    "val distData = sc.parallelize(data) //RDD oluştu Normally, Spark tries to set the number of partitions automatically based on your cluster. However, you can also set it manually by passing it as a second parameter to parruldu \n",
    "// ve paralel işlem yapılabilir artık."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel collection' larda önemli bir konuda bu RDD' nin kaç tane partition' a bölüneceği. Spark normalde partion' lama işlemlerini kendi yaparmış. Ama elle biz de verebilirmişiz. Elle vermek istersek `sc.parallelize(data, 10)` bu şekilde yapabiliriz.\n",
    "\n",
    "> Bazı yerlerde `partions` yerine `slices` ifadesi geçebilirmiş."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [External Datasets](https://spark.apache.org/docs/latest/rdd-programming-guide.html#external-datasets)\n",
    "\n",
    "Spark can create distributed datasets from any storage source supported by Hadoop, including your local file system, HDFS, Cassandra, HBase, Amazon S3, etc. Spark supports text files, SequenceFiles, and any other Hadoop InputFormat.\n",
    "\n",
    "Text file RDDs can be created using ***SparkContext***’s ***textFile*** method. This method takes a URI for the file (either a local path on the machine, or a hdfs://, s3a://, etc URI) and reads it as a collection of lines. Here is an example invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.rdd.RDD\n",
       "distFİle: org.apache.spark.rdd.RDD[String] = ../README.md MapPartitionsRDD[1] at textFile at <console>:27\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD;\n",
    "\n",
    "val distFİle: RDD[String] = sc.textFile(\"../README.md\") //distFile' in türünü atamasını Scala' nın bulması yerine\n",
    "// kendim atadığım için compile edilirken daha hızlı çalışacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on reading files with Spark:\n",
    "- Bir tane ana bilgisayar var ve ona bağlı köle bilgisayarlar (worker node) var. Ana bilgisayarın local' ındeki file' a köle bilgisayarlar tabiki de erişemeyecek. Erişebilmesi için ya dosyayayı workerlara kopyala ya da internet üzerinden erişmelerini sağla\n",
    "- All of Spark’s file-based input methods, including textFile, support running on directories, compressed files, and wildcards as well. For example, you can use textFile(\"/my/directory\"), textFile(\"/my/directory/*.txt\"), and textFile(\"/my/directory/*.gz\").\n",
    "- `textFile` metoduna isteğe bağlı RDD' nin partition' ını belirlemek için ikinci bir parametre daha verebiliyorsun. Default olarak bu partition' lara bölme işlemini `Spark zaten dosyadaki her bir block için bir tane partition oluşturarak yapıyor (HDFS' te her bir block 128MB' tır)`. İşte textFile metodunun ikinci parametresi sayesinde bu sayıyı arttırabiliyoruz. block değerinden aşağı bir partition sayısı belirleyemiyoruz. Default block size: 128MB. block size 256MB yapılamaz. `Default partition değeri 5 ise bu değeri parametre ile 4 yapamazsın. Çünkü partiton size' ı 128MB' den büyük olur.`\n",
    "\n",
    "> Devamıda vardı yazmadım. İlgili olan başlığa tıklayarak gerekli linke gidebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [RDD Operations](https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-operations)\n",
    "\n",
    "RDD' ler iki tür işleme destek verirler:\n",
    "- **transformation**: var olan bir RDD' den yeni bir RDD elde etme.\n",
    "- **actions**: Bir RDD' den belli hesaplamalar ile driver program' a bir değer döndürülmesi işlemleri.\n",
    "\n",
    "Transformation işlemleri ile oluşan RDD' ler hemen oluşturulmazlarmış(transformation işlemleri saklanırmış). Eğer bir action gelirse RDD oluşturulur ve daha sonra action işlemi gerçekleştirilirmiş. Bu Spark' a verimlilik katarmış (Ben ikna olmadım).\n",
    "\n",
    "Default olarak her action işlemi ile RDD oluşur ve üzerinden işlem yapılırmış ama istersek oluşan RDD' yi ***persist*** hale getirebiliyormuşuz: `action` ya da `persist` metodları ile. Eğer RDD üzerinde çok işlem yapılacaksa persist hale getirmek verimliliği arttır. (Buna ikna oldum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Basic](https://spark.apache.org/docs/latest/rdd-programming-guide.html#basics)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
