{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29d463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85341998",
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = 'Python Spark SQL basic example'\n",
    "\n",
    "spark_jars = '/home/sade/.local/share/DBeaverData/drivers/maven/maven-central/org.postgresql/postgresql-42.2.5.jar'\n",
    "# spark_jars: Postgres' ye bağlanmak için gereken bir şey. Veritabanı işlemleri için DBaver kullanıyorum.\n",
    "# Bu jar' ı DBaver kendi indiriyor. Spark içinde bu jar gerekliydi ben de DBaver' ın indirdiği jar' ı verdim.\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.jars\", spark_jars) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70944c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL' den veri çekme.\n",
    "\n",
    "format_ = 'jdbc' # Ne olduğuna dair bir bilgim yok.\n",
    "url = 'jdbc:postgresql://localhost:5432/postgres' # Postgre' ye bağlanmak için gereken host, port ve db adı.\n",
    "query = '(select * from postgres_table) pt' # Veritabanından çekilecek sorgu. Buraya sadece isimde gelebiliyor.\n",
    "user = 'postgres' # DB kullanıcı adı\n",
    "password = '\"123\"' # DB şifre\n",
    "driver = 'org.postgresql.Driver' # Ne olduğunu bilmiyorum. Benim baktığım örnekte Oracle' a bağlanıyordu. \n",
    "# Ben de o örneğe bakarak bunu BDaver' dan kopyaladım. \n",
    "\n",
    "\n",
    "# Sorgu çekiliyor ve gelen cevap bir DataFrame' e dönüştürülüyor.\n",
    "read_table = spark.read \\\n",
    "    .format(format_) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", query) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57fabb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_table type:  <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"read_table type: \", type(read_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb21a262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+-----------+----------+\n",
      "|      event|           messageid|  userid|  productid|    source|\n",
      "+-----------+--------------------+--------+-----------+----------+\n",
      "|ProductView|435784df-1a3c-4fc...| user-78| product-99|   desktop|\n",
      "|ProductView|920b451e-b364-42f...|user-228|product-523|   desktop|\n",
      "|ProductView|a9f9ef41-5f52-4c2...|user-233|product-759|mobile-web|\n",
      "|ProductView|2af77044-3c4a-429...|user-486|product-604|   desktop|\n",
      "|ProductView|4e12d021-d66f-4f3...| user-71| product-70|   desktop|\n",
      "|ProductView|1ce6faca-818d-408...| user-90| product-20|mobile-web|\n",
      "|ProductView|38ce0527-dc5e-434...|user-234| product-72|mobile-app|\n",
      "|ProductView|eaccc257-5f7a-43c...|user-220|product-622|mobile-web|\n",
      "|ProductView|dfaee9bb-42d9-483...|user-451| product-24|   desktop|\n",
      "|ProductView|62b88fb6-6249-4c7...| user-10|product-155|mobile-app|\n",
      "|ProductView|981c19e5-2e7c-451...| user-60|product-169|mobile-web|\n",
      "|ProductView|dff5dbde-593a-4cd...|user-165|product-535|mobile-web|\n",
      "|ProductView|0a1a81ce-7fa8-406...|user-392|product-754|mobile-app|\n",
      "|ProductView|55bdc84a-1b72-4d8...|user-115|product-384|   desktop|\n",
      "|ProductView|40efdbf5-3730-46a...|  user-9| product-71|mobile-web|\n",
      "|ProductView|98bb31c2-41fb-46c...|user-117|product-207|   desktop|\n",
      "|ProductView|271e3cb4-570b-456...|user-282|product-176|mobile-app|\n",
      "|ProductView|f84c5b67-cbea-4f7...|user-261| product-61|mobile-web|\n",
      "|ProductView|1355bbbc-c2a4-40a...| user-47|product-584|   desktop|\n",
      "|ProductView|8d7a0c8b-fcd2-468...| user-79|product-127|mobile-web|\n",
      "+-----------+--------------------+--------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read_table' ın içindeki veriler\n",
    "read_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7326f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+-----------+----------+\n",
      "|      event|           messageid|  userid|  productid|    source|\n",
      "+-----------+--------------------+--------+-----------+----------+\n",
      "|ProductView|435784df-1a3c-4fc...| user-78| product-99|   desktop|\n",
      "|ProductView|920b451e-b364-42f...|user-228|product-523|   desktop|\n",
      "|ProductView|a9f9ef41-5f52-4c2...|user-233|product-759|mobile-web|\n",
      "|ProductView|2af77044-3c4a-429...|user-486|product-604|   desktop|\n",
      "|ProductView|4e12d021-d66f-4f3...| user-71| product-70|   desktop|\n",
      "|ProductView|1ce6faca-818d-408...| user-90| product-20|mobile-web|\n",
      "|ProductView|38ce0527-dc5e-434...|user-234| product-72|mobile-app|\n",
      "|ProductView|eaccc257-5f7a-43c...|user-220|product-622|mobile-web|\n",
      "|ProductView|dfaee9bb-42d9-483...|user-451| product-24|   desktop|\n",
      "|ProductView|62b88fb6-6249-4c7...| user-10|product-155|mobile-app|\n",
      "|ProductView|981c19e5-2e7c-451...| user-60|product-169|mobile-web|\n",
      "|ProductView|dff5dbde-593a-4cd...|user-165|product-535|mobile-web|\n",
      "|ProductView|0a1a81ce-7fa8-406...|user-392|product-754|mobile-app|\n",
      "|ProductView|55bdc84a-1b72-4d8...|user-115|product-384|   desktop|\n",
      "|ProductView|40efdbf5-3730-46a...|  user-9| product-71|mobile-web|\n",
      "|ProductView|98bb31c2-41fb-46c...|user-117|product-207|   desktop|\n",
      "|ProductView|271e3cb4-570b-456...|user-282|product-176|mobile-app|\n",
      "|ProductView|f84c5b67-cbea-4f7...|user-261| product-61|mobile-web|\n",
      "|ProductView|1355bbbc-c2a4-40a...| user-47|product-584|   desktop|\n",
      "|ProductView|8d7a0c8b-fcd2-468...| user-79|product-127|mobile-web|\n",
      "+-----------+--------------------+--------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Şimdi sorgu çekme işlemi daha hızlı olsun diye bir tane method yazalım\n",
    "\n",
    "def spark_query(\n",
    "    query: str,\n",
    "    format_: str = 'jdbc',\n",
    "    url: str = 'jdbc:postgresql://localhost:5432/postgres',\n",
    "    user: str = 'postgres',\n",
    "    password: str = '\"123\"',\n",
    "    driver: str = 'org.postgresql.Driver'\n",
    "):\n",
    "    return spark.read \\\n",
    "        .format(format_) \\\n",
    "        .option(\"url\", url) \\\n",
    "        .option(\"dbtable\", query) \\\n",
    "        .option(\"user\", user) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .option(\"driver\", driver) \\\n",
    "        .load()\n",
    "\n",
    "# Şimdi deniyelim ve çektiği verileri göstersin\n",
    "read_table_method = spark_query(query='(select * from postgres_table) pt')\n",
    "\n",
    "read_table_method.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd90ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanırım Spark' ın kendine ait bir sorgu dili var. Çünkü bu şekildeki normal veritabanı sorguları çalışmıyor.\n",
    "spark_query(query='SELECT * FROM postgres_table')\n",
    "# Veridiği hata: ERROR: syntax error at or near \"SELECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e668834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark ile elde ettiğimiz veriler üzerinde bazı işlemler yapma\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "\n",
    "split_user_id = f.split(read_table['userid'], '-') # userid kolonunu -' ye göre parçalıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c31f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "print(type(split_user_id)) # Ne bilmiyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a654cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_product_id = f.split(read_table[\"productid\"], \"-\") # productid kolonunu -' ye göre parçalıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d686bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|userid|productid|\n",
      "+------+---------+\n",
      "|    78|       99|\n",
      "|   228|      523|\n",
      "|   233|      759|\n",
      "|   486|      604|\n",
      "|    71|       70|\n",
      "|    90|       20|\n",
      "|   234|       72|\n",
      "|   220|      622|\n",
      "|   451|       24|\n",
      "|    10|      155|\n",
      "|    60|      169|\n",
      "|   165|      535|\n",
      "|   392|      754|\n",
      "|   115|      384|\n",
      "|     9|       71|\n",
      "|   117|      207|\n",
      "|   282|      176|\n",
      "|   261|       61|\n",
      "|    47|      584|\n",
      "|    79|      127|\n",
      "+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Şimdi buradaki işlem sonunda userid ve productid den yeni bir DF oluşturuyoruz ama arka planda \n",
    "# ne dönüyor bilmiyorum.\n",
    "result_df = read_table.select(\n",
    "    split_user_id.getItem(1).alias(\"userid\"),\n",
    "    split_product_id.getItem(1).alias(\"productid\")\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef9094bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şimdi elde ettiğimiz DF' ı PostgreSQL' e yazalım.\n",
    "# Burası tam olarak ne yapar bilmiyorum.\n",
    "\n",
    "write_table = 'spark_postgres'\n",
    "\n",
    "result_df.write.format(format_) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", write_table) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .mode('append') \\ # Acaba veritabanının içini boşaltıp doldurma özelliği var mı? Başka hangi mod' lar var?\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etlPySpark",
   "language": "python",
   "name": "etlpyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
